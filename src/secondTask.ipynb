{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x2-qolR3UA8e",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def get_validation_generator(eval_batch_size=1):\n",
    "    validation_dir = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/validation\" #change with your path (sharedFolder->secondTaskData->validationion\n",
    "    transform_dir = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/transform\" #change with your path (sharedFolder->secondTaskData->transform\n",
    "    flip = True\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_transform_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    random = True\n",
    "    seed = 42\n",
    "    shape = (256, 256)\n",
    "    shape_hr = (1024, 1024)\n",
    "    validation_generator_x = test_transform_datagen.flow_from_directory(\n",
    "        transform_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=eval_batch_size,\n",
    "        class_mode=None, shuffle=True, seed=seed)\n",
    "    validation_generator_y = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=shape_hr,\n",
    "        batch_size=eval_batch_size,\n",
    "        class_mode=None, shuffle=True, seed=seed)\n",
    "    validation_generator = zip(validation_generator_x, validation_generator_y)\n",
    "    return validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1EeZiyZTUWP9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def get_train_generator(train_batch_size=1):\n",
    "    train_dir = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/training\" #change with your path (sharedFolder->secondTaskData->training\n",
    "    transform_train_dir = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/transform_train\" #change with your path (sharedFolder->secondTaskData->transform_train\n",
    "    flip = True\n",
    "    # encode the images in float vector. \n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       horizontal_flip=flip, vertical_flip=flip)\n",
    "\n",
    "    train_transform_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                                 horizontal_flip=flip, vertical_flip=flip)\n",
    "\n",
    "    random = True\n",
    "    seed = 42\n",
    "    shape = (256, 256)\n",
    "    shape_hr = (1024, 1024)\n",
    "    train_generator_x = train_transform_datagen.flow_from_directory(\n",
    "        transform_train_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=train_batch_size,\n",
    "        class_mode=None, shuffle=True, seed=seed)\n",
    "    train_generator_y = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size=shape_hr,\n",
    "                                                          batch_size=train_batch_size,\n",
    "                                                          class_mode=None, shuffle=True, seed=seed)\n",
    "\n",
    "    train_generator = zip(train_generator_x, train_generator_y)\n",
    "    return train_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W5dZ9cocUp-H",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "0e14fc51-0709-4d15-b0e2-9041eaf64d2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "def get_image_generators(train_batch_size=1, eval_batch_size=1):\n",
    "    train_generator = get_train_generator(train_batch_size)\n",
    "    validation_generator = get_validation_generator(eval_batch_size)\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UxrqnSd23UaS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def CNN(create_model=True):\n",
    "    if create_model:\n",
    "        #make generator\n",
    "        print(\"CREATION MODEL\")\n",
    "        generatorInput = layers.Input(shape=(256, 256, 3))\n",
    "        generator = layers.Conv2D(64, (9, 9), input_shape=(256, 256, 3), padding='same', activation='relu')(\n",
    "            generatorInput)  #n1\n",
    "\n",
    "        generator = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(generator)\n",
    "        generator = layers.BatchNormalization(momentum=0.8)(generator)\n",
    "\n",
    "        generator = layers.Conv2D(64, (3, 3), padding='same')(generator)\n",
    "        generator = layers.BatchNormalization(momentum=0.8)(generator)\n",
    "\n",
    "        #loop\n",
    "        for a in range(7):\n",
    "            generator = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(generator)\n",
    "            generator = layers.BatchNormalization(momentum=0.8)(generator)\n",
    "\n",
    "        generator = layers.Conv2D(64, (3, 3), padding='same', activation='relu', name='exitLoop')(generator)\n",
    "        generator = layers.BatchNormalization(momentum=0.8)(generator)\n",
    "\n",
    "        generator = layers.Conv2DTranspose(128, 3, strides=2, padding='same')(generator)\n",
    "        generator = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(generator)\n",
    "\n",
    "        generator = layers.Conv2DTranspose(64, 3, strides=2, padding='same')(generator)\n",
    "        generator = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(generator)\n",
    "\n",
    "        generatorOutput = layers.Conv2D(3, (9, 9), padding='same', activation='tanh')(generator)\n",
    "\n",
    "        gen_model = models.Model(generatorInput, generatorOutput, name=\"generator\")\n",
    "\n",
    "        print(\"generator\")\n",
    "        gen_model.summary()\n",
    "        lossToUse = 'mse'\n",
    "        optimizerToUse = Adam(0.0001, 0.5)\n",
    "        gen_model.compile(optimizer=optimizerToUse, loss=lossToUse)\n",
    "        return gen_model\n",
    "    else:\n",
    "        print(\"LOADING MODEL\")\n",
    "        #gen_model = models.load_model('D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/temporaryModel.h5')\n",
    "        path = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/\"  #change with your path (sharedFolder->secondTaskData)\n",
    "        gen_model = models.load_model(path + 'GeneratorFitNew.h5')\n",
    "    return gen_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nMb7cwh1pY5P",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def save_model(model, path=\"\", name=\"name\"):\n",
    "    model.save(path + name + '.h5')\n",
    "    model.save_weights(path + name + 'Weights.h5')\n",
    "    model_json = model.to_json()\n",
    "    with open(path + name + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    plot_model(model, to_file=path + name + 'Model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    from contextlib import redirect_stdout\n",
    "\n",
    "    with open(path + name + 'Parameter.txt', \"w\") as model_summary:\n",
    "        with redirect_stdout(model_summary):\n",
    "            model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nZPCYcmKn18V",
    "colab_type": "code",
    "cellView": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "def save_result(numberEpoch=0, path=\"\"):\n",
    "    os.makedirs(path + 'result/' + str(numberEpoch),\n",
    "                exist_ok=True)\n",
    "    path_pure = path + 'PureImage'\n",
    "    os.makedirs(path_pure, exist_ok=True)\n",
    "    t, v = get_image_generators()\n",
    "    for i in range(100):\n",
    "        x_to_transform, y_hight = next(v)\n",
    "        generated = model.predict(x_to_transform)\n",
    "        img_hr = img_as_ubyte(y_hight[0])\n",
    "        img_to_transform = img_as_ubyte(x_to_transform[0])\n",
    "        img_generated = img_as_ubyte(generated[0])\n",
    "        f, axarr = plt.subplots(1, 3)\n",
    "        plt.rcParams[\"figure.figsize\"] = [20, 9]\n",
    "        axarr[0].set_title(\"Original LR\")\n",
    "        axarr[0].grid(False)\n",
    "        axarr[0].imshow(img_to_transform, aspect='auto')\n",
    "        axarr[1].set_title(\"Generated HR\")\n",
    "        axarr[1].grid(False)\n",
    "        axarr[1].imshow(img_generated, aspect='auto')\n",
    "        axarr[2].set_title(\"HR\")\n",
    "        axarr[2].grid(False)\n",
    "        axarr[2].imshow(img_hr, aspect='auto')\n",
    "        f.savefig(path + 'result/' + str(numberEpoch) + '/' + str(\n",
    "            numberEpoch) + '(' + str(i) + ').png', dpi=150, bbox_inches='tight')\n",
    "        plt.close(f)\n",
    "        imageio.imwrite(path_pure + '/' + str(numberEpoch) + '(' + str(i) + ').png', img_generated)\n",
    "        print(\"saved image ============>\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "afdgdQCLOlxP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class PartialSaver(Callback):\n",
    "    def __init__(self, save_step, previousStep, path):\n",
    "        self.v = get_validation_generator()\n",
    "        self.batch_seen = 100\n",
    "        self.pred_step = save_step\n",
    "        self.previous = previousStep\n",
    "        self.path = path\n",
    "        self.path_res = self.path + \"PartialResults\"\n",
    "        self.path_pure = self.path + 'PartialResults/PureImage'\n",
    "        os.makedirs(self.path_res, exist_ok=True)\n",
    "        os.makedirs(self.path_pure, exist_ok=True)\n",
    "\n",
    "def on_epoch_end(self, epoch, logs={}):\n",
    "    path = self.path\n",
    "    if epoch % 1000 == 0:\n",
    "        if epoch > 999:\n",
    "            print(\"1000 epochs completed\")\n",
    "        else:\n",
    "            print(\"STARTED\")\n",
    "        print(\"EPOCH: \", epoch, \" with loss values: \", logs)\n",
    "\n",
    "    if epoch % self.pred_step == 0:\n",
    "        x_to_transform, y_hight = next(self.v)\n",
    "        self.batch_seen -= 1\n",
    "        generated = model.predict(x_to_transform)\n",
    "        img_to_transform = img_as_ubyte(x_to_transform[0])\n",
    "        img_hr = img_as_ubyte(y_hight[0])\n",
    "        img_generated = img_as_ubyte(generated[0])\n",
    "        plt.rcParams[\"figure.figsize\"] = [20, 9]\n",
    "        f, axarr = plt.subplots(1, 3)\n",
    "        axarr[0].set_title(\"Original LR\")\n",
    "        axarr[0].grid(False)\n",
    "        axarr[0].imshow(img_to_transform, aspect='auto')\n",
    "        axarr[1].set_title(\"Generated HR\")\n",
    "        axarr[1].grid(False)\n",
    "        axarr[1].imshow(img_generated, aspect='auto')\n",
    "        axarr[2].set_title(\"HR\")\n",
    "        axarr[2].grid(False)\n",
    "        axarr[2].imshow(img_hr, aspect='auto')\n",
    "        f.savefig(self.path_res + '/' + str(\n",
    "            epoch + self.previous) + '.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close(f)\n",
    "        imageio.imwrite(self.path_pure + '/' + str(epoch + self.previous) + '.png', img_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jPOliceUACrt",
    "colab_type": "code",
    "colab": {},
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 1 classes.\nFound 800 images belonging to 1 classes.\nFound 100 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 1 classes.\nCREATION MODEL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         (None, 256, 256, 3)       0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 256, 256, 64)      15616     \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nexitLoop (Conv2D)            (None, 256, 256, 64)      36928     \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 256, 256, 64)      256       \n_________________________________________________________________\nconv2d_transpose_3 (Conv2DTr (None, 512, 512, 128)     73856     \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 512, 512, 128)     147584    \n_________________________________________________________________\nconv2d_transpose_4 (Conv2DTr (None, 1024, 1024, 64)    73792     \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 1024, 1024, 64)    36928     \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 1024, 1024, 3)     15555     \n=================================================================\nTotal params: 735,171\nTrainable params: 733,891\nNon-trainable params: 1,280\n_________________________________________________________________\nFound 100 images belonging to 1 classes.\nFound 100 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be starting......\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "create_model = True\n",
    "previous_steps = 0\n",
    "epoch_to_launch = 5000\n",
    "launch_in_night = False\n",
    "partial_image_saving = 50\n",
    "partial_model_saving = 4\n",
    "step_for_epoch = 10\n",
    "validation_steps = 2\n",
    "path = \"D:/GoogleDrive/Machine_Learning_Project-Classification+SRCNN/secondTaskData/\" #change with ypur path (sharedFolder->secondTaskData\n",
    "train_generator, validation_generator = get_image_generators()\n",
    "model = CNN(create_model=create_model)\n",
    "\n",
    "model_saver = ModelCheckpoint(path + 'temporaryModel.h5', monitor='val_loss', verbose=0,\n",
    "                              save_best_only=False, save_weights_only=False, mode='auto', period=partial_model_saving)\n",
    "\n",
    "#COMMENT THE ABOVE LINE IF YOU DO NOT WANT TO SAVE THE PARTIAL IMAGE RESULT AND REMOVE IT IN THE CALLBACKS IN FIT\n",
    "callback_saver = PartialSaver(partial_image_saving, previous_steps, path)\n",
    "print(\"to be starting......\")\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=step_for_epoch,\n",
    "                              epochs=epoch_to_launch,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps, verbose=0,\n",
    "                              callbacks=[callback_saver, model_saver])\n",
    "print(\"terminated training\")\n",
    "print(\"begin saving.....\")\n",
    "save_model(model, path, name=\"GeneratorFitNew\")\n",
    "save_result(previous_steps + epoch_to_launch, path)\n",
    "print(\"end saving. Completed\")\n",
    "if launch_in_night:\n",
    "    os.system(\"shutdown /s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SRCNN_dm.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
